#!/usr/bin/env python
#
# pyfit
#

import sys
import json
from dataclasses import dataclass
from multiprocessing import Pool
from datetime import datetime
from itertools import islice
from pathlib import Path

import pandas as pd
from lmfit import Parameters

from typing import Optional


@dataclass
class PyFitterResults:
    path: 'PathQuery'
    config: dict
    fit_results: Parameters
    subset: str
    mrc: Optional[str]


def arg_parser():
    from argparse import ArgumentParser
    parser = ArgumentParser()
    parser.add_argument("input",
                        help="file to fit")
    parser.add_argument("-o", "--output",
                        nargs='?',
                        default=None,
                        help="Output fitresult json file")
    parser.add_argument("--chi2",
                        action='store_true',
                        help="file to fit")
    parser.add_argument("--fitrange",
                        type=float,
                        default=0.19,
                        help="symmetric limit to fit")
    parser.add_argument("--mrc-path",
                        nargs='?',
                        default=None,
                        help="file to fit")
    parser.add_argument("--fitter",
                        default='FitterGauss6',
                        help="Name of the fitter class to use")
    parser.add_argument("--subset",
                        default=None,
                        help="Only fit a named subset of the data")
    parser.add_argument("-c", "--count",
                        type=int,
                        default=None,
                        help="Limit on number of plots to fit")
    parser.add_argument("--limit",
                        type=int,
                        dest='count')
    return parser


def main(argv=None):
    if argv is None:
        argv = sys.argv[1:]
    args = arg_parser().parse_args(argv)
    if sys.path[0] != '':
        sys.path.insert(0, '')

    from femtofitter.fit import parallel_fit_all
    from femtofitter import pyfitter
    from stumpy.utils import walk_matching
    from ROOT import gSystem, TFile

    if gSystem.Load("build/libFemtoFitter.so") < 0:
        print("Could not load libFemtoFitter")
        return 1

    tfile = TFile.Open(args.input)
    if not tfile:
        return 1

    filename = Path(args.input).resolve()

    if args.output:
        dest = Path(args.output)
    else:
        dest_filename = "pyfitres-%s.json" % tfile.GetName()
        dest_dir = Path("fit-results")
        dest_dir.mkdir(exist_ok=True, parents=True)
        dest = dest_dir / dest_filename
        # todo: Check if dest exists and warn user?

    mrc_path = args.mrc_path

    fit_range = args.fitrange

    fitter = getattr(pyfitter, args.fitter)

    paths = walk_matching(tfile, "AnalysisQ3D/cfg*/*/*/*/*")

    work = ((fitter, str(filename), path, fit_range, args.subset, mrc_path)
             for path, _  in paths)

    # only take first few work units
    if args.count:
        work = islice(work, args.count)

    def process_fit_result(results: PyFitterResults):
        from femtofitter import flatten_config
        if not isinstance(results, list):
            results = [results]

        dfs = []
        for result in results:
            # print("processing: ", result)
            tmp: dict = result.path.as_dict()
            fit_results = result.fit_results
            params = fit_results.params
            for key in params.keys():
                p = params[key]
                tmp[key] = p.value
                tmp[key + "_err"] = p.stderr

            tmp['subset'] = result.subset
            df = pd.DataFrame([tmp])

            configs = []
            for k,v in result.config.items():
                cfg = k.partition('/')[2]
                configs.append(flatten_config(v))
                configs[-1]['cfg'] = cfg

            config = pd.DataFrame(configs)
            # print("CONFIG>>", config)

            dfs.append(df)

        df = pd.concat(dfs)
        return dict(df=df, config=config)

    with Pool() as pool:
        # results = pool.starmap_async(do_fit, work, callback=process_fit_result)
        # results = pool.imap_unordered(lambda args: process_fit_result(do_fit(*args)), work)
        # results = pool.map(lambda args: process_fit_result(do_fit(*args)), work)

        results = [process_fit_result(r) for r in pool.starmap(do_fit, work)]

    df = pd.concat([r['df'] for r in results])
    config = pd.concat([r['config'] for r in results])
    # reduce to unique
    config = pd.DataFrame([val.iloc[0] for _, val in config.groupby('cfg')])

    output_data = {
        'filename': str(filename),
        'timestamp': datetime.now().isoformat(timespec='milliseconds'),
        'df': df.to_dict(orient='records'),
        'config': config.to_dict(orient='records'),
    }

    print(f"writing output to {dest}")

    with dest.open('w') as ofile:
        json.dump(output_data, ofile, indent=1)

    return 0

def do_fit_caller(args):
    return do_fit(*args)

def do_fit(fitter,
           filename,
           path,
           fit_range,
           subset=None,
           mrc_path=None,
    ) -> Optional[PyFitterResults]:

    from ROOT import gSystem, TFile
    from femtofitter import PathQuery
    from femtofitter.fit import get_configuration_json
    from femtofitter.pyfitter import MomentumResolutionCorrector

    if gSystem.Load("build/libFemtoFitter.so") < 0:
        return None

    tfile = TFile.Open(filename)
    if not tfile:
        return None

    tdir = tfile.Get(path)
    if not tdir:
        return None

    if mrc_path:
        if mrc_path == filename:
            mrc_tfile = tfile
        else:
            mrc_tfile = TFile.Open(str(mrc_path))

        mrc = MomentumResolutionCorrector(filename=mrc_tfile)
    else:
        mrc = None

    query = PathQuery.from_path(path)
    results = query.as_dict()
    print("Fitting:", filename, path)

    config = get_configuration_json(tfile, [query])
    from femtofitter.pyfitter import Data3D

    data = Data3D.From(tdir, fit_range)
    if subset is None:
        pass
    elif subset == 'cowboy':
        data = data.cowboy_subset()
    elif subset == 'sailor':
        data = data.sailor_subset()
    else:
        print(f"Unknown subset {subset!r}; ignoring.")
        subset = None

    if mrc_path:
        mrc.apply(data, query.pair, query.kt, query.magfield)

    fitter = fitter(data)
    mini = fitter.pml_minimizer(nan_policy='omit')

    results_0 = mini.minimize(method='nelder')
    fit_results = mini.minimize(method='leastsq', params=results_0.params)
    fit_results = mini.minimize(method='leastsq', params=fit_results.params)

    return PyFitterResults(query, config, fit_results, subset, mrc_path)


if __name__ == "__main__":
    exit(main())
